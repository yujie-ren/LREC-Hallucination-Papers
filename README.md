# LREC-Hallucination-Papers

### LREC-COLING-2024

1. A Cause-Effect Look at Alleviating Hallucination of Knowledge-grounded Dialogue Generation [[pdf]](https://aclanthology.org/2024.lrec-main.9/)  
(THU, propose a solution for alleviating the hallucination in KGD)  
2. Benchmarking Hallucination in Large Language Models Based on Unanswerable Math Word Problem [[pdf]](https://aclanthology.org/2024.lrec-main.196/)  
(ECNU, Dataset of 5200 questions, Math problem)  
3. Detecting Hallucination and Coverage Errors in Retrieval Augmented Generation for Controversial Topics [[pdf]](https://aclanthology.org/2024.lrec-main.423/)  
(Google, Detect hallucination in RAG)  
4. Detection, Diagnosis, and Explanation: A Benchmark for  Chinese Medial Hallucination Evaluation [[pdf]](https://aclanthology.org/2024.lrec-main.428/)  
(PKU, Hallucination detection benchmark, Chinese medical evaluation)  
5. German Also Hallucinates! Inconsistency Detection in News Summaries with the Absinth Dataset [[pdf]](https://aclanthology.org/2024.lrec-main.680/)  
(ETH, Hallucination detection dataset, German news summarization)  
6. Halwasa: Quantify and Analyze Hallucinations in Large Language Models:  Arabic as a Case Study [[pdf]](https://aclanthology.org/2024.lrec-main.705/)  
()
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTIwNDQ4ODM2MDIsLTEyNDg2MjQwODUsLT
E2NjU4NTcxODksNzk3NTMyODQ3LC0xODM1MjI0Nzk5LC0xNDQ5
MjM1ODEwLC0yMDY3MTM0OTddfQ==
-->